{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar and Building Forecasting\n",
    "## Load prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import keras\n",
    "from methods import read_pickle\n",
    "from methods import find_index_v2\n",
    "from methods import RM_model\n",
    "from methods import NN_model\n",
    "from methods import building_methods\n",
    "data_cleanned_v2 = read_pickle(path_name = 'data\\data_processed_phase2.pickle')\n",
    "## GPU check\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Prediction:\n",
    "### Due to the observed capacity increase from May 2020 on Solar 3, we replaced partial data of Solar3 with Solar2's data (They shared the same start time and end time)\n",
    "- This is an experiense and domain knowledge based calibration, so we separatly disscused this in notebook Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = pd.to_datetime('2020-05-20 00:00:00')\n",
    "clip_index = find_index_v2(data_cleanned_v2, 'Solar2', datetime)\n",
    "data_cleanned_v2['Solar3']['Solar3'][:clip_index] = data_cleanned_v2['Solar2']['Solar2'][:clip_index] \n",
    "data_cleanned_v2['Solar5'] =  data_cleanned_v2['Solar5'][96*300:]\n",
    "data_cleanned_v2['Solar0'] =  data_cleanned_v2['Solar0'][96*120:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function for replicating solar genearion predictions\n",
    "- Result might be slightly different depending on the training process\n",
    "- For the simplicity, we didn't specified attentions and similarity thresholds for the RM discovery as we did in the previous paper, which might further improve the accuracy but also need further studies on different solars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RM_prediction(data_cleanned, user_type, NN_type):\n",
    "    ## motifs discovery range and training range (noramlly the same)\n",
    "    train_days = int(len(data_cleanned[user_type])/96)\n",
    "    RM = RM_model(data_cleanned)\n",
    "    motifs_range = [-24*4*train_days,0]\n",
    "    train_range = [-24*4*train_days,0] \n",
    "    ## Here we didn't specified attentions and similarity thresholds for the RM discovery \n",
    "    motifs, motif_data, motif_pattern, temperature_motif, cloudcover_motif, humidity_motif, radiation_motif, times_motif = RM.motifs_discovery(user_type, motifs_range)\n",
    "    ### training data\n",
    "    train_data = data_cleanned[user_type][train_range[0]:].copy() if train_range[1] ==0 else data_cleanned[user_type][train_range[0]:train_range[1]].copy()\n",
    "    y_train = train_data[user_type].values.reshape(train_days, 96) if user_type.find('Solar') != -1 else train_data['consumption'].values.reshape(train_days, 96)\n",
    "    cloudcover_train = train_data ['total_cloud_cover (0-1)'].values.reshape(train_days, 96)\n",
    "    humidity_train = train_data ['relative_humidity ((0-1))'].values.reshape(train_days, 96)\n",
    "    radiation_train = train_data ['surface_solar_radiation (W/m^2)'].values.reshape(train_days, 96)\n",
    "    temperature_train = train_data['temperature (degC)'].values.reshape(train_days, 96)\n",
    "    temperature_train = [i-temperature_motif.values for i in temperature_train] \n",
    "    cloudcover_train = [i-cloudcover_motif.values for i in cloudcover_train] \n",
    "    humidity_train = [i-humidity_motif.values for i in humidity_train]\n",
    "    radiation_train = [i-radiation_motif.values for i in radiation_train]\n",
    "    times_train = pd.CategoricalIndex(train_data.index.time).codes.astype(float)\n",
    "    sun_cycle_train = np.maximum(np.sin(2*np.pi *(times_train+16)/96), 0 ).reshape(train_days, 96)\n",
    "    times_train = times_train.reshape(train_days, 96)\n",
    "    weekday_train = pd.CategoricalIndex(train_data.index.weekday).codes.astype(float).reshape(train_days, 96)\n",
    "    motifs_train = [motif_pattern for i in range(train_days)]\n",
    "    motifs_train = np.array(motifs_train)\n",
    "    month_train = pd.CategoricalIndex(train_data.index.month).codes.astype(float).reshape(train_days, 96)\n",
    "    year_cycle_train = abs(np.sin(2*np.pi*(month_train-5)/24))\n",
    "    year_cycle_train = year_cycle_train.reshape(train_days, 96)\n",
    "    weekend_train = np.where((weekday_train == 5) | (weekday_train == 6), True, False)\n",
    "    if user_type.find('Solar') != -1:\n",
    "        if user_type = 'Solar0':\n",
    "            ## Solar 0 has data less than a year hence the yearly cycle needs to be adjusted \n",
    "            year_cycle_train = abs(np.sin(2*np.pi*(month_train-1)/24))\n",
    "        x_train = np.column_stack((motifs_train, cloudcover_train, radiation_train, times_train, year_cycle_train)) \n",
    "        x_train_cnn = np.dstack((motifs_train, temperature_train, cloudcover_train, radiation_train, year_cycle_train))\n",
    "    else:\n",
    "        occupancy_motif = motif_data['occupancy (0-1)'][motifs['motif_position']:motifs['motif_position']+96]\n",
    "        occupancy_train = train_data['occupancy (0-1)'].values.reshape(train_days, 96)\n",
    "        occupancy_train = [i-occupancy_motif.values for i in occupancy_train] \n",
    "        x_train = np.column_stack((motifs_train, temperature_train, occupancy_train, humidity_train, cloudcover_train, radiation_train, weekday_train, times_train)) \n",
    "        x_train_cnn = np.dstack((motifs_train, weekend_train, temperature_train, radiation_train, month_train))\n",
    "    Solar_pre_model = NN_model(x_train_cnn, y_train, 96) \n",
    "    model_cnn = Solar_pre_model.CNN_series() if NN_type == 'CNN' else Solar_pre_model.ResNet()\n",
    "    ######### nov data\n",
    "    nov_length = 30*4*24\n",
    "    nov_days = 30\n",
    "    # oct_motifs, oct_motif_data, oct_motif_pattern, oct_temperature_motif, oct_cloudcover_motif, oct_humidity_motif, oct_radiation_motif, oct_times_motif = motifs_discovery(data_cleanned, user_type, predict_range)\n",
    "    weather_data = data_cleanned['weather'][:nov_length].copy()\n",
    "    cloudcover_nov = weather_data ['total_cloud_cover (0-1)'].values.reshape(nov_days, 96)\n",
    "    humidity_nov = weather_data ['relative_humidity ((0-1))'].values.reshape(nov_days, 96)\n",
    "    radiation_nov = weather_data ['surface_solar_radiation (W/m^2)'].values.reshape(nov_days, 96)\n",
    "    temperature_nov = weather_data['temperature (degC)'].values.reshape(nov_days, 96)\n",
    "    temperature_nov = [i-temperature_motif.values for i in temperature_nov] \n",
    "    cloudcover_nov = [i-cloudcover_motif.values for i in cloudcover_nov] \n",
    "    humidity_nov = [i-humidity_motif.values for i in humidity_nov]\n",
    "    radiation_nov = [i-radiation_motif.values for i in radiation_nov]\n",
    "    times_nov = pd.CategoricalIndex(weather_data.index.time).codes.astype(float)\n",
    "    ###### For building\n",
    "    # sun_cycle_nov = np.maximum(np.sin(2*np.pi *(times_nov+16)/96), 0 ).reshape(nov_days, 96)\n",
    "    ###### For solar\n",
    "    times_nov= times_nov.reshape(nov_days, 96)\n",
    "    weekday_nov = pd.CategoricalIndex(weather_data.index.weekday).codes.astype(float).reshape(nov_days, 96)\n",
    "    motifs_nov = [motif_pattern for i in range(nov_days)]\n",
    "    motifs_nov = np.array(motifs_nov)\n",
    "    month_nov = pd.CategoricalIndex(weather_data.index.month).codes.astype(float).reshape(nov_days, 96)\n",
    "    month_nov = month_train[-1][-1]+1\n",
    "    year_cycle_nov = abs(np.sin(2*np.pi*(month_nov-5)/24))\n",
    "    year_cycle_nov = year_cycle_nov.reshape(nov_days, 96)\n",
    "    weekend_nov = np.where((weekday_nov == 5) | (weekday_nov == 6), True, False)\n",
    "    if user_type.find('Solar') != -1:\n",
    "        if user_type = 'Solar0':\n",
    "            year_cycle_nov = abs(np.sin(2*np.pi*(month_nov-1)/24))\n",
    "        x_nov = np.column_stack((motifs_nov, cloudcover_nov, radiation_nov, times_nov, month_nov)) \n",
    "        x_nov_cnn = np.dstack((motifs_nov, temperature_nov, cloudcover_nov, radiation_nov, year_cycle_nov)) \n",
    "    else:\n",
    "        occupancy_nov = data_cleanned['occupancy'][:nov_length].values.reshape(nov_days, 96)\n",
    "        times_nov[252:] = (times_nov[252:]+4)%96\n",
    "        nov_occupancy_motif = motif_data['occupancy (0-1)'][motifs['motif_position']:motifs['motif_position']+96]\n",
    "        occupancy_nov = [i-oct_occupancy_motif.values for i in occupancy_oct] \n",
    "        x_nov = np.column_stack((motifs_nov, temperature_nov, occupancy_nov, humidity_nov, cloudcover_nov, radiation_nov, weekday_nov, times_nov)) \n",
    "        x_nov_cnn = np.dstack((motifs_nov, weekend_nov, temperature_nov, radiation_nov,  month_nov))\n",
    "    ### early stop settings\n",
    "    test_epochs = 20000\n",
    "    test_patience = 1000\n",
    "    model_cnn.fit(x_train_cnn, y_train, epochs = test_epochs, batch_size=30, verbose = 0, callbacks=[keras.callbacks.EarlyStopping(monitor='loss', patience=test_patience)])\n",
    "    y_predict_cnn = model_cnn.predict(x_nov_cnn).reshape(nov_days*96)\n",
    "    return model_cnn, x_nov_cnn, y_predict_cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the solar prediction \n",
    "### Two types of NNs can be used (2-layer 1D-CNN and ResNet)\n",
    "### Trained models and used input features can be saved based on needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_NNs = {\n",
    "    'Solar0':'ResNet',\n",
    "    'Solar1':'CNN',\n",
    "    'Solar2':'ResNet',\n",
    "    'Solar3':'ResNet',\n",
    "    'Solar4':'CNN',\n",
    "    'Solar5':'ResNet',\n",
    "}\n",
    "solar_predictions = {}\n",
    "for i in solar_NNs.keys():\n",
    "    model_solar, x_nov, y_nov= RM_prediction(data_cleanned_v2, i, solar_NNs[i])\n",
    "    solar_predictions[i] = [max(j,0) for j in y_nov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Prediction\n",
    "- We replaced buildings' holiday data (AFL) from the real dataset with predicted values to remove the abnormal disturbance from the holiday\n",
    "- We also tried to replace it with weekends but the holidays have special profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw building data\n",
    "def read_raw_building_data():\n",
    "    # Load pre-processed data for phase 2\n",
    "    raw_building_df = data_cleanned_v2\n",
    "\n",
    "    # Consider time zone change from AEST --> AEDT\n",
    "    time_zone_change = pd.to_datetime('2020-10-03 16:00')\n",
    "    for key in raw_building_df:\n",
    "        if key.find('Building') != -1:\n",
    "            raw_building_df[key] = raw_building_df[key].rename(columns={\"consumption\": key})\n",
    "            raw_building_df[key] = raw_building_df[key].reset_index()\n",
    "            pd.options.mode.chained_assignment = None\n",
    "            \n",
    "            # +1 hour for all time instances after 2020-10-03 16:00\n",
    "            for i in range(len(raw_building_df[key])):\n",
    "                if raw_building_df[key]['index'][i] >= time_zone_change:\n",
    "                    raw_building_df[key]['index'][i] = raw_building_df[key]['index'][i] + timedelta(hours=1)\n",
    "            raw_building_df[key] = raw_building_df[key].set_index('index')\n",
    "    \n",
    "    # Replace the holiday daytime real data with the predicted data\n",
    "    # Holiday: Oct 23 2020 (daytime)--> Index: [-879 -831]\n",
    "    oct_prediction = pd.read_pickle(\"data/submissions_phase1.pickle\")\n",
    "    predicted_building1 = oct_prediction['submission_Oct9']['Building1']\n",
    "    predicted_building3 = oct_prediction['submission_Oct9']['Building3']\n",
    "    predicted_building6 = oct_prediction['submission_Oct9']['Building6']\n",
    "\n",
    "    raw_building_df['Building1']['Building1'][-879:-831] = predicted_building1[-879:-831].values\n",
    "    raw_building_df['Building3']['Building3'][-879:-831] = predicted_building3[-879:-831].values\n",
    "    raw_building_df['Building6']['Building6'][-879:-831] = predicted_building6[-879:-831].values\n",
    "\n",
    "    return raw_building_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function for replicating building consumption predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def building_prediction(dict_df, drop_name=None):\n",
    "    ### STL decomposition for building 1, 3 and 6\n",
    "    ### Tree-based learning directly on building 0 and 5\n",
    "    ### Flat prediction of 1 on building 4\n",
    "    building_predictor = building_methods(dict_df)\n",
    "    y_prediction = []\n",
    "    for key in dict_df:\n",
    "        \n",
    "        if key.find('Solar') != -1 or key == 'occupancy' or key == 'weather':\n",
    "            continue\n",
    "        \n",
    "        if drop_name is not None and key in drop_name:\n",
    "            continue\n",
    "        \n",
    "        print('Predicting for', key)\n",
    "        dict_df = building_predictor.building_decomposition(key)\n",
    "        \n",
    "        if key == 'Building1' or key == 'Building3' or key == 'Building6':\n",
    "            SVM_input = ['tempC', 'tempC_2', 'humidity', 'cloudcover', 'time', 'dew_tempC', 'dew_tempC_2', 'isweekend', \n",
    "                         'weekday', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'time_group', 'time_group_2']\n",
    "            RF_input = ['tempC', 'humidity', 'cloudcover', 'dew_tempC', 'time', 'weekday', 'isweekend', 'time_group']\n",
    "            training_length = 24*4*31\n",
    "\n",
    "            # Collect prediction data from different machine learning methods (RF, SVM, GB)\n",
    "            # Each output is a dict containing results from different components (residual, seasonal, trend, original)\n",
    "            y_dict_RF, y_dict_SVM, y_dict_GB = building_predictor.train_unseen_STL(key, RF_input, SVM_input, training_length)\n",
    "            \n",
    "            y_main = y_dict_GB['residual'] + y_dict_GB['trend'] + y_dict_RF['seasonal']\n",
    "            if key == 'Building1':\n",
    "                base_consumption = 12\n",
    "            if key == 'Building3':\n",
    "                base_consumption = 350\n",
    "            if key == 'Building6':\n",
    "                base_consumption = 29\n",
    "            \n",
    "            # Half the peak prediction during midday of 03 Nov 2020 holiday\n",
    "            y_main = building_predictor.holiday_halving(y_main, base_consumption)\n",
    "            \n",
    "        elif key == 'Building0':\n",
    "            SVM_input = ['tempC', 'tempC_2', 'humidity', 'cloudcover', 'time', 'dew_tempC', 'dew_tempC_2', 'isweekend', \n",
    "                         'weekday', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'time_group', 'time_group_2']\n",
    "            RF_input = ['tempC', 'humidity', 'cloudcover', 'radiation', 'time', 'weekday', 'isweekend', 'dew_tempC', 'time_group']\n",
    "            training_length = 24*4*13\n",
    "\n",
    "            # Collect prediction data from different machine learning methods (RF, SVM, GB)\n",
    "            y_main, y_SVM_temp, y_GB_temp = building_predictor.train_unseen_tree(key, RF_input, SVM_input, training_length)\n",
    "            # Increase the prediction values for first few intervals\n",
    "            y_main[0:37] += 20\n",
    "            \n",
    "        elif key == 'Building4':\n",
    "            # A flat prediction of 1 on Building 4\n",
    "            y_main = np.ones(96*30)\n",
    "            \n",
    "        elif key == 'Building5':\n",
    "            SVM_input = ['tempC', 'tempC_2', 'humidity', 'cloudcover', 'time', 'dew_tempC', 'dew_tempC_2', 'isweekend', \n",
    "                         'weekday', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'time_group', 'time_group_2']\n",
    "            RF_input = ['tempC', 'humidity', 'cloudcover', 'time', 'weekday', 'isweekend', 'time_group']\n",
    "            training_length = 24*4*31\n",
    "\n",
    "            # Collect prediction data from different machine learning methods (RF, SVM, GB)\n",
    "            y_main, y_SVM_temp, y_GB_temp = building_predictor.train_unseen_tree( key, RF_input, SVM_input, training_length)\n",
    "            \n",
    "        y_prediction.append(y_main)\n",
    "        \n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the building consumption predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = read_raw_building_data()\n",
    "y_building_predict = building_prediction(dict_df, drop_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "index_name =['Building0', 'Building1', 'Building3', 'Building4', 'Building5', 'Building6']\n",
    "index_name.extend(solar_predictions.keys())\n",
    "for i in range(len(y_building_predict)):\n",
    "    prediction_list.append(y_building_predict[i])\n",
    "for j in solar_predictions.keys():\n",
    "    prediction_list.append(solar_predictions[j])\n",
    "total_predicted_df = pd.DataFrame(prediction_list, index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('outputs'):\n",
    "    os.makedirs('outputs')\n",
    "total_predicted_df.to_csv('outputs/forecasting.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('FRESNOB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3188a0a0452a5a4c0d70147b17766d45ebd0a954f15630618bcd568112ac39b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
